{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3772f54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20876057",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dir):\n",
    "    data_dict = {}\n",
    "    if not os.path.exists(dir):\n",
    "        raise FileExistsError(f\"Directory not found.\")\n",
    "    for filename in os.listdir(dir):\n",
    "        if filename.endswith('.csv'):\n",
    "            filepath = os.path.join(dir, filename)\n",
    "            df = pd.read_csv(filepath)\n",
    "            cleaned_column = {col: col.strip('%').strip() for col in df.columns}\n",
    "            df.rename(columns=cleaned_column, inplace =True)\n",
    "            df = df.astype(\"float\")\n",
    "            data_dict[filename] = df\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cc53793",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "def create_missing_value(df, missing_fraction=0.1, seed=None):    \n",
    "    df_with_missing = df.copy()\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    mask = np.random.rand(*df.shape) < missing_fraction\n",
    "    df_with_missing = df_with_missing.mask(mask)\n",
    "    \n",
    "    return df_with_missing\n",
    "\n",
    "def longest_notna(df):\n",
    "    notna_mask = df.notna().all(axis=1)  # Ensure all columns are not NaN\n",
    "    group_id = (notna_mask != notna_mask.shift()).cumsum()\n",
    "\n",
    "    # Filter only the True blocks (where all values are not NaN)\n",
    "    valid_blocks = df[notna_mask].copy()\n",
    "    valid_blocks['group'] = group_id[notna_mask]\n",
    "\n",
    "    # Find the longest group\n",
    "    longest_group = valid_blocks['group'].value_counts().idxmax()\n",
    "\n",
    "    # Return the longest block\n",
    "    return valid_blocks[valid_blocks['group'] == longest_group].drop(columns='group')\n",
    "\n",
    "def knn_mean(ts, n=4):\n",
    "    ts = np.array(ts)\n",
    "    out = np.copy(ts)\n",
    "    for i, val in enumerate(ts):\n",
    "        if np.isnan(val):\n",
    "            lower = max(0, i - n)\n",
    "            upper = min(len(ts), i + n + 1)\n",
    "            neighbors = ts[lower:i].tolist() + ts[i+1:upper].tolist()\n",
    "            neighbors = [x for x in neighbors if not np.isnan(x)]\n",
    "            out[i] = np.mean(neighbors) if neighbors else np.nan\n",
    "    return out\n",
    "\n",
    "def seasonal_mean(series, season_lag, lr=0.7):\n",
    "\n",
    "    out = series.copy()\n",
    "    for i in range(len(series)):\n",
    "        if pd.isna(series.iloc[i]):\n",
    "            # Previous seasonal values\n",
    "            prev_seasons = series.iloc[i - season_lag::-season_lag]\n",
    "            if pd.isna(prev_seasons.mean()):\n",
    "                # Combine previous and forward seasonal values\n",
    "                forward_seasons = series.iloc[i + season_lag::season_lag]\n",
    "                seasonal_values = pd.concat([prev_seasons, forward_seasons])\n",
    "            else:\n",
    "                seasonal_values = prev_seasons\n",
    "            out.iloc[i] = seasonal_values.mean() * lr\n",
    "    return out\n",
    "\n",
    "def handle_missing(df, percent):\n",
    "    # Remove columns have missing data above threshhold.\n",
    "    missing_percent = df.isnull().mean()\n",
    "    df_filtered = df.loc[:, missing_percent<percent]\n",
    "    print(f\"Filtered all features having missing value > 20%\")\n",
    "    print(f\"Number of features removed: {len(df.columns)-len(df_filtered.columns)}\")\n",
    "\n",
    "    notna_mask = df_filtered.notna()\n",
    "\n",
    "    missing_df = create_missing_value(df_filtered.loc(notna_mask))\n",
    "\n",
    "    for col in missing_df.columns:\n",
    "\n",
    "        imputation_dict = {}\n",
    "        imputation_dict[\"backward/forward_fill\"] = missing_df[col].bfill().ffill()\n",
    "        imputation_dict[\"linear_interpolation\"] = missing_df[col].interpolate(method = 'linear', axis = 0, limit_direction = 'forward')\n",
    "        imputation_dict[\"quadaric_interpolation\"] = missing_df[col].interpolate(method = 'cubicspline')\n",
    "        imputation_dict[\"knn_mean\"] = knn_mean(missing_df[col], 8)\n",
    "        imputation_dict[\"seasonal_mean\"] = seasonal_mean(missing_df[col], season_lag = 12, lr = 1.25)\n",
    "\n",
    "        for key, value in imputation_dict.items():\n",
    "            print(f\"Evaluation from {key}\")\n",
    "            print(f\"MAE: {mean_absolute_error(missing_df[col],value)}\")\n",
    "            print(f\"MSE: {mean_squared_error(missing_df[col],value)}\")\n",
    "            print(f\"R^2: {r2_score(missing_df[col],value)}\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ea26b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thanh\\AppData\\Local\\Temp\\ipykernel_14736\\297146114.py:8: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,14,15,17,18,20,22,23,25,27,29,31,33,35,37,39,41,43,44,45,47,49) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       CO2air\n",
      "0       474.0\n",
      "1       470.0\n",
      "2       482.0\n",
      "3       472.0\n",
      "4       469.0\n",
      "...       ...\n",
      "20546   663.0\n",
      "20547   683.0\n",
      "20548   726.0\n",
      "20549   719.0\n",
      "20550   694.0\n",
      "\n",
      "[20551 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = '../'\n",
    "GREENHOUSE_TEAM = \"Digilog\"\n",
    "team_folder_path = os.path.join(DATA_PATH,GREENHOUSE_TEAM)\n",
    "team_df = load_data(team_folder_path)\n",
    "df = team_df[\"GreenhouseClimate.csv\"][[\"CO2air\"]]\n",
    "# Get the longest block with all notna values\n",
    "clean_block = longest_notna(df)\n",
    "print(clean_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec387980",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thanh\\AppData\\Local\\Temp\\ipykernel_18864\\297146114.py:8: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,14,15,17,18,20,22,23,25,27,29,31,33,35,37,39,41,43,44,45,47,49) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded data from Digilog\n",
      "Filtered all features having missing value > 20%\n",
      "Number of features removed: 4\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'DataFrame'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_18864\\3695690140.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      5\u001b[39m team_df = load_data(team_folder_path)\n\u001b[32m      6\u001b[39m \n\u001b[32m      7\u001b[39m print(f\"Successfully loaded data from {GREENHOUSE_TEAM}\")\n\u001b[32m      8\u001b[39m team_df[\u001b[33m\"GreenhouseClimate.csv\"\u001b[39m][\u001b[33m\"CO2air\"\u001b[39m].head(\u001b[32m5\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m handle_missing(team_df[\u001b[33m\"GreenhouseClimate.csv\"\u001b[39m], \u001b[32m0.2\u001b[39m)\n",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_18864\\2541015831.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(df, percent)\u001b[39m\n\u001b[32m     46\u001b[39m     print(f\"Number of features removed: {len(df.columns)-len(df_filtered.columns)}\")\n\u001b[32m     47\u001b[39m \n\u001b[32m     48\u001b[39m     notna_mask = df_filtered.notna()\n\u001b[32m     49\u001b[39m \n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m     missing_df = create_missing_value(df_filtered.loc(notna_mask))\n\u001b[32m     51\u001b[39m \n\u001b[32m     52\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;28;01min\u001b[39;00m missing_df.columns:\n\u001b[32m     53\u001b[39m \n",
      "\u001b[32mc:\\Users\\thanh\\miniconda3\\envs\\ds-project\\Lib\\site-packages\\pandas\\core\\indexing.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, axis)\u001b[39m\n\u001b[32m    734\u001b[39m         \u001b[38;5;66;03m# we need to return a copy of ourselves\u001b[39;00m\n\u001b[32m    735\u001b[39m         new_self = type(self)(self.name, self.obj)\n\u001b[32m    736\u001b[39m \n\u001b[32m    737\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m738\u001b[39m             axis_int_none = self.obj._get_axis_number(axis)\n\u001b[32m    739\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    740\u001b[39m             axis_int_none = axis\n\u001b[32m    741\u001b[39m         new_self.axis = axis_int_none\n",
      "\u001b[32mc:\\Users\\thanh\\miniconda3\\envs\\ds-project\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(cls, axis)\u001b[39m\n\u001b[32m    573\u001b[39m     @classmethod\n\u001b[32m    574\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m _get_axis_number(cls, axis: Axis) -> AxisInt:\n\u001b[32m    575\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    576\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m cls._AXIS_TO_AXIS_NUMBER[axis]\n\u001b[32m--> \u001b[39m\u001b[32m577\u001b[39m         \u001b[38;5;28;01mexcept\u001b[39;00m KeyError:\n\u001b[32m    578\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m ValueError(f\"No axis named {axis} for object type {cls.__name__}\")\n",
      "\u001b[31mTypeError\u001b[39m: unhashable type: 'DataFrame'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "DATA_PATH = '../'\n",
    "GREENHOUSE_TEAM = \"Digilog\"\n",
    "\n",
    "team_folder_path = os.path.join(DATA_PATH,GREENHOUSE_TEAM)\n",
    "team_df = load_data(team_folder_path)\n",
    "\n",
    "print(f\"Successfully loaded data from {GREENHOUSE_TEAM}\")\n",
    "team_df[\"GreenhouseClimate.csv\"][\"CO2air\"].head(5)\n",
    "handle_missing(team_df[\"GreenhouseClimate.csv\"], 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0717f445",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "def adf_test(timeseries):\n",
    "    print('Result of Augmented Dickey Fuller: ')\n",
    "    df_test= adfuller(timeseries, autolag = \"AIC\")\n",
    "    df_output = pd.Series(df_test[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations'])\n",
    "    for key, value in df_test[4].items():\n",
    "        df_output['Critical Value (%s)'%key] = value\n",
    "    print(df_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "28c0f22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of Augmented Dickey Fuller: \n",
      "Test Statistic           -1.313535e+01\n",
      "p-value                   1.466031e-24\n",
      "#Lags Used                5.300000e+01\n",
      "Number of Observations    4.680100e+04\n",
      "Critical Value (1%)      -3.430490e+00\n",
      "Critical Value (5%)      -2.861602e+00\n",
      "Critical Value (10%)     -2.566803e+00\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "adf_test(df_climate[\"int_red_sp\"].astype(\"float\").dropna())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
