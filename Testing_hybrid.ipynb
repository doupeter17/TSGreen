{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-29T02:21:18.397303Z",
     "start_time": "2025-05-29T02:21:15.246338Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from torch.utils.data import random_split\n",
    "from torch.amp import autocast, GradScaler"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T02:21:18.522491Z",
     "start_time": "2025-05-29T02:21:18.434265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(torch.__version__)              # 2.5.1+cu118\n",
    "print(torch.cuda.is_available())      # True\n",
    "print(torch.cuda.get_device_name(0))  # Your GPU name"
   ],
   "id": "73c4aebcbca40e2e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu118\n",
      "True\n",
      "NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Data Prep",
   "id": "d8fe90f69eaa9f29"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T02:21:18.799372Z",
     "start_time": "2025-05-29T02:21:18.785350Z"
    }
   },
   "cell_type": "code",
   "source": [
    "file_paths = {\n",
    "    \"GreenhouseClimate\": \"D:/Bitchass Agri stupid af shjt/Reference/GreenhouseClimate.csv\",\n",
    "    \"GrodanSens\": \"D:/Bitchass Agri stupid af shjt/Reference/GrodanSens.csv\",\n",
    "    \"Resources\": \"D:/Bitchass Agri stupid af shjt/Reference/Resources.csv\",\n",
    "    \"Weather\": \"D:/Bitchass Agri stupid af shjt/Weather/Weather.csv\",\n",
    "    \"CropParameters\": \"D:/Bitchass Agri stupid af shjt/Reference/CropParameters.csv\"\n",
    "}"
   ],
   "id": "6c35c3cb99f54b66",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T02:21:20.040615Z",
     "start_time": "2025-05-29T02:21:18.817573Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dfs = {}\n",
    "for name, path in file_paths.items():\n",
    "    df = pd.read_csv(path, low_memory=False)\n",
    "    df.columns = df.columns.str.strip().str.replace('\\t', '')\n",
    "    if '%time' in df.columns or '%Time' in df.columns:\n",
    "            time_col = '%time' if '%time' in df.columns else '%Time'\n",
    "            df[time_col] = pd.to_numeric(df[time_col], errors='coerce')\n",
    "            df['Date'] = pd.to_datetime(df[time_col], origin='1899-12-30', unit='D')\n",
    "    elif 'time' in df.columns:\n",
    "        df['time'] = pd.to_numeric(df['time'], errors='coerce')\n",
    "        df['Date'] = pd.to_datetime(df['time'], origin='1899-12-30', unit='D')\n",
    "    elif 'Date' in df.columns:\n",
    "        if pd.api.types.is_numeric_dtype(df['Date']):\n",
    "            df['Date'] = pd.to_datetime(df['Date'], origin='1899-12-30', unit='D', errors='coerce')\n",
    "        else:\n",
    "            df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "    else:\n",
    "        df['Date'] = pd.NaT\n",
    "    df.loc[:, df.columns != 'Date'] = df.loc[:, df.columns != 'Date'].apply(pd.to_numeric, errors='coerce')\n",
    "    dfs[name] = df\n"
   ],
   "id": "b00cbee80faaa6fb",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T02:21:20.085728Z",
     "start_time": "2025-05-29T02:21:20.071319Z"
    }
   },
   "cell_type": "code",
   "source": "print(dfs['Resources']['Date'])",
   "id": "aed07a62e6b192fe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     2019-12-16\n",
      "1     2019-12-17\n",
      "2     2019-12-18\n",
      "3     2019-12-19\n",
      "4     2019-12-20\n",
      "         ...    \n",
      "161   2020-05-25\n",
      "162   2020-05-26\n",
      "163   2020-05-27\n",
      "164   2020-05-28\n",
      "165   2020-05-29\n",
      "Name: Date, Length: 166, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T02:21:20.178540Z",
     "start_time": "2025-05-29T02:21:20.159023Z"
    }
   },
   "cell_type": "code",
   "source": [
    "soil_cols = ['EC_slab1', 'EC_slab2', 'WC_slab1', 'WC_slab2', 't_slab1', 't_slab2']\n",
    "indoor_cols = ['Tair', 'Rhair', 'CO2air', 'HumDef', 'PipeLow', 'VentLee', 'Ventwind', 'Tot_PAR', 'Tot_PAR_Lamps', 'EC_drain_PC']\n",
    "weather_cols = ['Tout', 'Rhout', 'Iglob', 'PARout', 'Pyrgeo', 'Rain', 'Winddir', 'Windsp']\n",
    "crop_cols = ['Stem_elong', 'Stem_thick', 'Cum_trusses', 'stem_dens', 'plant_dens']"
   ],
   "id": "8663c1bb4abe6541",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T02:21:20.224612Z",
     "start_time": "2025-05-29T02:21:20.210276Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def reshape_sliding(df, cols, steps, stride=1):\n",
    "    df = df.copy()\n",
    "    df[cols] = df[cols].astype(np.float32)\n",
    "    arr = df[cols].values\n",
    "    if len(arr) < steps:\n",
    "        return np.empty((0, steps, len(cols)))\n",
    "    windows = [arr[i:i + steps] for i in range(0, len(arr) - steps + 1, stride)]\n",
    "    return np.stack(windows)"
   ],
   "id": "1a418929ad2cbd45",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T02:21:20.270744Z",
     "start_time": "2025-05-29T02:21:20.257332Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_delta(mask):\n",
    "    B, T, D = mask.shape\n",
    "    delta = np.zeros((B, T, D), dtype=np.float32)\n",
    "    for b in range(B):\n",
    "        for d in range(D):\n",
    "            last_obs = 0\n",
    "            for t in range(T):\n",
    "                if mask[b, t, d] == 1:\n",
    "                    delta[b, t, d] = 0\n",
    "                    last_obs = 0\n",
    "                else:\n",
    "                    last_obs += 1\n",
    "                    delta[b, t, d] = last_obs\n",
    "    return delta"
   ],
   "id": "11d262616ad1269d",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T02:21:20.825177Z",
     "start_time": "2025-05-29T02:21:20.302622Z"
    }
   },
   "cell_type": "code",
   "source": [
    "base = dfs['GrodanSens'].copy()\n",
    "base = base.dropna(subset=['Date']).sort_values('Date').reset_index(drop=True)\n",
    "merge_partners = ['GreenhouseClimate', 'Weather', 'CropParameters']\n",
    "for name in merge_partners:\n",
    "    df = dfs[name].copy().dropna(subset=['Date']).sort_values('Date')\n",
    "    if '%time' in df.columns:\n",
    "        df.drop(columns=['%time'], inplace=True)\n",
    "    try:\n",
    "        base = pd.merge_asof(base, df, on='Date', direction='nearest', tolerance=pd.Timedelta('1D'))\n",
    "    except ValueError as e:\n",
    "        print(f\"[ERROR] Skipped {name} during merge: {e}\")\n",
    "resources_df = dfs['Resources'].copy().dropna(subset=['Date']).sort_values('Date').reset_index(drop=True)\n",
    "resources_df['Energy'] = resources_df[['Heat_cons', 'ElecHigh', 'ElecLow']].astype(np.float32).sum(axis=1)\n",
    "resources_df = resources_df[['Date', 'Energy']]\n",
    "resources_df['Date'] = resources_df['Date'].dt.floor('D')\n",
    "base['Date'] = base['Date'].dt.floor('D')\n",
    "base = pd.merge_asof(base.sort_values('Date'), resources_df, on='Date', direction='nearest', tolerance=pd.Timedelta('1D'))\n",
    "base = base.dropna(subset=['Energy']).reset_index(drop=True)"
   ],
   "id": "ea733b5f3ccd54bb",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T02:21:45.595624Z",
     "start_time": "2025-05-29T02:21:20.857711Z"
    }
   },
   "cell_type": "code",
   "source": [
    "steps = 288  # full day (5 min x 288 = 24 hours)\n",
    "# --- Sliding window time-series ---\n",
    "soil_data = reshape_sliding(base, soil_cols, steps=steps, stride=1)\n",
    "soil_mask = (~np.isnan(soil_data)).astype(np.float32)\n",
    "soil_delta = compute_delta(soil_mask)\n",
    "soil_data = np.nan_to_num(soil_data)\n",
    "indoor_data = reshape_sliding(base, indoor_cols, steps=steps, stride=1)\n",
    "weather_data = reshape_sliding(base, weather_cols, steps=steps, stride=1)\n",
    "# --- Crop is static per day, align with sliding windows ---\n",
    "crop_data_raw = base[crop_cols].astype(np.float32).to_numpy()\n",
    "crop_data = crop_data_raw[steps - 1:]  # align with window end points"
   ],
   "id": "42011d3421f68fdc",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T02:22:00.327196Z",
     "start_time": "2025-05-29T02:21:45.657680Z"
    }
   },
   "cell_type": "code",
   "source": [
    "window_end_dates = base['Date'].iloc[steps - 1:].reset_index(drop=True)\n",
    "targets = []\n",
    "valid_indices = []\n",
    "for i in range(len(soil_data)):\n",
    "    end_date = window_end_dates[i].floor('D')\n",
    "    match = resources_df[resources_df['Date'] == (end_date + pd.Timedelta(days=1))]\n",
    "    if not match.empty:\n",
    "        energy_val = match['Energy'].values[0]\n",
    "        if not np.isnan(energy_val):\n",
    "            targets.append(energy_val.astype(np.float32))\n",
    "            valid_indices.append(i)"
   ],
   "id": "308b1aaab5f20db4",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T02:22:00.405419Z",
     "start_time": "2025-05-29T02:22:00.391590Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"Matched {len(targets)} out of {len(soil_data)} total windows\")",
   "id": "44f2743c54f7d8af",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched 47233 out of 47522 total windows\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T02:22:03.483265Z",
     "start_time": "2025-05-29T02:22:00.453804Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if valid_indices:\n",
    "    soil_data = soil_data[valid_indices]\n",
    "    soil_mask = soil_mask[valid_indices]\n",
    "    soil_delta = soil_delta[valid_indices]\n",
    "    indoor_data = indoor_data[valid_indices]\n",
    "    weather_data = weather_data[valid_indices]\n",
    "    crop_data = crop_data[valid_indices]\n",
    "    targets = torch.tensor(np.array(targets), dtype=torch.float32).unsqueeze(1)\n",
    "    dataset = TensorDataset(\n",
    "        torch.tensor(soil_data, dtype=torch.float32),\n",
    "        torch.tensor(soil_mask, dtype=torch.float32),\n",
    "        torch.tensor(soil_delta, dtype=torch.float32),\n",
    "        torch.tensor(indoor_data, dtype=torch.float32),\n",
    "        torch.tensor(weather_data, dtype=torch.float32),\n",
    "        torch.tensor(crop_data, dtype=torch.float32),\n",
    "        targets\n",
    "    )\n",
    "    dataloader = DataLoader(dataset, batch_size=64, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    print(f\"Dataloader ready: {len(dataset)} labeled windows with next-day energy targets\")\n",
    "else:\n",
    "    print(\"No labeled windows found for energy prediction.\")"
   ],
   "id": "8c7f677c496244d4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader ready: 47233 labeled windows with next-day energy targets\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T02:22:09.312106Z",
     "start_time": "2025-05-29T02:22:03.777370Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sample_batch = next(iter(dataloader))\n",
    "soil_x, soil_mask, soil_delta, indoor_x, weather_x, crop_x, target_y = sample_batch"
   ],
   "id": "bd6e49c2caa42240",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T02:22:09.448990Z",
     "start_time": "2025-05-29T02:22:09.435056Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check your full training target tensor\n",
    "print(\"Any NaN in y tensor:\", torch.isnan(target_y).any())"
   ],
   "id": "6bac954efc7660dc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any NaN in y tensor: tensor(False)\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T02:22:09.556980Z",
     "start_time": "2025-05-29T02:22:09.542243Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check shapes\n",
    "print(f\"Soil shape:        {soil_x.shape}\")\n",
    "print(f\"Soil mask shape:   {soil_mask.shape}\")\n",
    "print(f\"Soil delta shape:  {soil_delta.shape}\")\n",
    "print(f\"Indoor shape:      {indoor_x.shape}\")\n",
    "print(f\"Weather shape:     {weather_x.shape}\")\n",
    "print(f\"Crop shape:        {crop_x.shape}\")\n",
    "print(f\"Target shape:      {target_y.shape}\")"
   ],
   "id": "b05bad88e21165a3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soil shape:        torch.Size([64, 288, 6])\n",
      "Soil mask shape:   torch.Size([64, 288, 6])\n",
      "Soil delta shape:  torch.Size([64, 288, 6])\n",
      "Indoor shape:      torch.Size([64, 288, 10])\n",
      "Weather shape:     torch.Size([64, 288, 8])\n",
      "Crop shape:        torch.Size([64, 5])\n",
      "Target shape:      torch.Size([64, 1])\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T02:22:09.680009Z",
     "start_time": "2025-05-29T02:22:09.651527Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Lengths\n",
    "total_len = len(dataset)\n",
    "train_len = int(0.8 * total_len)\n",
    "val_len = int(0.1 * total_len)\n",
    "test_len = total_len - train_len - val_len  # handle rounding\n",
    "# Split dataset\n",
    "train, val, test = random_split(dataset, [train_len, val_len, test_len])\n",
    "# DataLoaders\n",
    "batch_size = 64  # or 64\n",
    "train_loader = DataLoader(train, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "test_loader = DataLoader(test, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "print(f\"Split sizes — Train: {len(train)}, Val: {len(val)}, Test: {len(test)}\")"
   ],
   "id": "db601efcba206ff1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split sizes — Train: 37786, Val: 4723, Test: 4724\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model",
   "id": "97c4cea9d8d2412d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T02:22:09.773878Z",
     "start_time": "2025-05-29T02:22:09.760358Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class FeatureNorm(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "    def forward(self, x):\n",
    "        return self.norm(x)"
   ],
   "id": "5ba4622d1f212abf",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T02:22:09.898611Z",
     "start_time": "2025-05-29T02:22:09.868589Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GRUD(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size=None, device=\"cpu\"):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.device = device\n",
    "        self.input_embed = nn.Linear(input_size, input_size)\n",
    "        self.gamma_x = nn.Parameter(torch.ones(input_size) * 0.1)\n",
    "        self.gamma_h = nn.Parameter(torch.ones(hidden_size) * 0.1)\n",
    "        self.z_gate = nn.Linear(input_size * 3 + hidden_size, hidden_size)\n",
    "        self.r_gate = nn.Linear(input_size * 3 + hidden_size, hidden_size)\n",
    "        self.h_tilde = nn.Linear(input_size * 3 + hidden_size, hidden_size)\n",
    "        self.output = nn.Sequential(\n",
    "            nn.LayerNorm(hidden_size),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_size, output_size) if output_size else nn.Identity()\n",
    "        )\n",
    "    def forward(self, x, x_mask, x_delta, x_mean=None):\n",
    "        B, T, D = x.shape\n",
    "        x = self.input_embed(x)\n",
    "        x = torch.nan_to_num(x, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        if x_mean is None:\n",
    "            x_mean = torch.mean(x, dim=1, keepdim=True).detach()\n",
    "        x_mean = torch.nan_to_num(x_mean, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        h = torch.zeros(B, self.hidden_size, device=self.device)\n",
    "        outputs = []\n",
    "        gamma_h = torch.exp(-F.relu(self.gamma_h)).unsqueeze(0).expand(B, -1)\n",
    "        gamma_h = torch.nan_to_num(gamma_h, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        for t in range(T):\n",
    "            x_t = x[:, t, :]\n",
    "            m_t = x_mask[:, t, :]\n",
    "            d_t = x_delta[:, t, :]\n",
    "            d_t = torch.clamp(d_t, 0.0, 100.0)\n",
    "            d_t = torch.nan_to_num(d_t, nan=0.0, posinf=100.0, neginf=0.0)\n",
    "            gamma_x = torch.exp(-F.relu(self.gamma_x) * d_t)\n",
    "            gamma_x = torch.nan_to_num(gamma_x, nan=1.0, posinf=1.0, neginf=0.0)\n",
    "            x_t_hat = m_t * x_t + (1 - m_t) * (gamma_x * x_mean.squeeze(1))\n",
    "            x_t_hat = torch.nan_to_num(x_t_hat, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "            h = gamma_h * h\n",
    "            h = torch.nan_to_num(h, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "            inputs = torch.cat([x_t_hat, m_t, d_t, h], dim=1)\n",
    "            inputs = torch.nan_to_num(inputs, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "            z = torch.sigmoid(self.z_gate(inputs))\n",
    "            r = torch.sigmoid(self.r_gate(inputs))\n",
    "            h_tilde = torch.tanh(self.h_tilde(torch.cat([x_t_hat, m_t, d_t, r * h], dim=1)))\n",
    "            h = (1 - z) * h + z * h_tilde\n",
    "            h = torch.nan_to_num(h, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "            outputs.append(h.unsqueeze(1))\n",
    "        outputs = torch.cat(outputs, dim=1)\n",
    "        pooled = outputs[:, -1, :]\n",
    "        pooled = torch.nan_to_num(pooled, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        return self.output(pooled)"
   ],
   "id": "fd7c1a7cbd46f7e6",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T02:22:09.990947Z",
     "start_time": "2025-05-29T02:22:09.976888Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MLPEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = torch.nan_to_num(x, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        return self.net(x)"
   ],
   "id": "12b43d5d9db9a2a2",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T02:22:10.083025Z",
     "start_time": "2025-05-29T02:22:10.069510Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SimpleGRU(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(input_dim, hidden_dim, batch_first=True)\n",
    "        self.out = nn.Sequential(\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = torch.nan_to_num(x, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        _, h = self.gru(x)\n",
    "        h = h[-1]\n",
    "        h = torch.nan_to_num(h, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        return self.out(h)"
   ],
   "id": "70cc47165e91a792",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T02:22:10.174535Z",
     "start_time": "2025-05-29T02:22:10.160989Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class AttentionFusion(nn.Module):\n",
    "    def __init__(self, input_dims, fusion_dim):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Sequential(\n",
    "            nn.Linear(sum(input_dims), fusion_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(fusion_dim, len(input_dims)),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "    def forward(self, features):\n",
    "        features = [torch.nan_to_num(f, nan=0.0, posinf=0.0, neginf=0.0) for f in features]\n",
    "        all_feat = torch.cat(features, dim=1)\n",
    "        all_feat = torch.nan_to_num(all_feat, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        weights = self.attn(all_feat)  # [B, num_modalities]\n",
    "        weighted = [f * weights[:, i:i+1] for i, f in enumerate(features)]\n",
    "        return torch.cat(weighted, dim=1)"
   ],
   "id": "2d1500895c9aaa28",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T02:22:10.267224Z",
     "start_time": "2025-05-29T02:22:10.253176Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class HybridAgriModel(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.soil_encoder = GRUD(config['soil_in'], config['soil_hidden'], config['branch_out'], device=config['device'])\n",
    "        self.env_encoder = SimpleGRU(config['indoor_in'] + config['weather_in'], 32, config['branch_out'])\n",
    "        self.crop_encoder = MLPEncoder(config['crop_in'], 16, config['branch_out'])\n",
    "        self.fusion = AttentionFusion([config['branch_out']] * 3, config['fusion_dim'])\n",
    "        self.head = nn.Sequential(\n",
    "            nn.LayerNorm(config['branch_out'] * 3),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(config['branch_out'] * 3, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, config['output_dim']),\n",
    "            nn.Softplus()\n",
    "        )\n",
    "    def forward(self, soil, mask, delta, indoor, weather, crop):\n",
    "        f1 = self.soil_encoder(soil, mask, delta)\n",
    "        f2 = self.env_encoder(torch.cat([indoor, weather], dim=2))\n",
    "        f3 = self.crop_encoder(crop)\n",
    "        f1 = torch.nan_to_num(f1, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        f2 = torch.nan_to_num(f2, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        f3 = torch.nan_to_num(f3, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        fused = self.fusion([f1, f2, f3])\n",
    "        fused = torch.nan_to_num(fused, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        return self.head(fused)"
   ],
   "id": "1b7ab3ff8d90c88e",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T02:22:10.343196Z",
     "start_time": "2025-05-29T02:22:10.330595Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config_virtual = {\n",
    "    'soil_in': 6,\n",
    "    'soil_hidden': 64,\n",
    "    'indoor_in': 10,\n",
    "    'weather_in': 8,\n",
    "    'crop_in': 5,\n",
    "    'branch_out': 64,\n",
    "    'fusion_dim': 128,\n",
    "    'output_dim': 1,\n",
    "    'device': 'cpu'\n",
    "}\n",
    "# === Dummy inputs that reflect your DataLoader ===\n",
    "B = 8\n",
    "sample_inputs = (\n",
    "    torch.rand(B, 20, config_virtual['soil_in']),       # soil_x\n",
    "    torch.ones(B, 20, config_virtual['soil_in']),       # soil_mask\n",
    "    torch.zeros(B, 20, config_virtual['soil_in']),      # soil_delta\n",
    "    torch.rand(B, 20, config_virtual['indoor_in']),     # indoor_x\n",
    "    torch.rand(B, 20, config_virtual['weather_in']),    # weather_x\n",
    "    torch.rand(B, config_virtual['crop_in'])            # crop_x\n",
    ")"
   ],
   "id": "f47b1bbd1e7467d9",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T02:22:10.451631Z",
     "start_time": "2025-05-29T02:22:10.438029Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def validate_model_structure(model, sample_inputs):\n",
    "    print(\"Model Architecture Validation:\\n\")\n",
    "    logs = []\n",
    "    def safe_shape(x):\n",
    "        if isinstance(x, torch.Tensor):\n",
    "            return list(x.shape)\n",
    "        elif isinstance(x, (list, tuple)) and isinstance(x[0], torch.Tensor):\n",
    "            return [list(t.shape) for t in x]\n",
    "        return str(type(x))\n",
    "    def hook_fn(module, input, output):\n",
    "        logs.append({\n",
    "            \"layer\": module.__class__.__name__,\n",
    "            \"input_shape\": safe_shape(input),\n",
    "            \"output_shape\": safe_shape(output)\n",
    "        })\n",
    "    hooks = [m.register_forward_hook(hook_fn) for m in model.modules()\n",
    "             if not isinstance(m, (nn.Sequential, nn.ModuleList)) and m != model]\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        model(*sample_inputs)\n",
    "    for i, log in enumerate(logs):\n",
    "        print(f\"{i:02d} - {log['layer']:20} | Input: {log['input_shape']} -> Output: {log['output_shape']}\")\n",
    "    for h in hooks:\n",
    "        h.remove()"
   ],
   "id": "5ea8d258ee6e1659",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T02:22:10.638729Z",
     "start_time": "2025-05-29T02:22:10.546529Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = HybridAgriModel(config_virtual)\n",
    "validate_model_structure(model, sample_inputs)"
   ],
   "id": "b3afcc40a8b34835",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Architecture Validation:\n",
      "\n",
      "00 - Linear               | Input: [[8, 20, 6]] -> Output: [8, 20, 6]\n",
      "01 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "02 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "03 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "04 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "05 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "06 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "07 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "08 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "09 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "10 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "11 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "12 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "13 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "14 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "15 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "16 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "17 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "18 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "19 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "20 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "21 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "22 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "23 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "24 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "25 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "26 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "27 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "28 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "29 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "30 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "31 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "32 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "33 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "34 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "35 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "36 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "37 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "38 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "39 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "40 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "41 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "42 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "43 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "44 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "45 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "46 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "47 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "48 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "49 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "50 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "51 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "52 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "53 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "54 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "55 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "56 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "57 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "58 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "59 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "60 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "61 - LayerNorm            | Input: [[8, 64]] -> Output: [8, 64]\n",
      "62 - Dropout              | Input: [[8, 64]] -> Output: [8, 64]\n",
      "63 - Linear               | Input: [[8, 64]] -> Output: [8, 64]\n",
      "64 - GRUD                 | Input: [[8, 20, 6], [8, 20, 6], [8, 20, 6]] -> Output: [8, 64]\n",
      "65 - GRU                  | Input: [[8, 20, 18]] -> Output: [[8, 20, 32], [1, 8, 32]]\n",
      "66 - LayerNorm            | Input: [[8, 32]] -> Output: [8, 32]\n",
      "67 - Dropout              | Input: [[8, 32]] -> Output: [8, 32]\n",
      "68 - Linear               | Input: [[8, 32]] -> Output: [8, 64]\n",
      "69 - SimpleGRU            | Input: [[8, 20, 18]] -> Output: [8, 64]\n",
      "70 - Linear               | Input: [[8, 5]] -> Output: [8, 16]\n",
      "71 - ReLU                 | Input: [[8, 16]] -> Output: [8, 16]\n",
      "72 - BatchNorm1d          | Input: [[8, 16]] -> Output: [8, 16]\n",
      "73 - Dropout              | Input: [[8, 16]] -> Output: [8, 16]\n",
      "74 - Linear               | Input: [[8, 16]] -> Output: [8, 64]\n",
      "75 - MLPEncoder           | Input: [[8, 5]] -> Output: [8, 64]\n",
      "76 - Linear               | Input: [[8, 192]] -> Output: [8, 128]\n",
      "77 - Tanh                 | Input: [[8, 128]] -> Output: [8, 128]\n",
      "78 - Linear               | Input: [[8, 128]] -> Output: [8, 3]\n",
      "79 - Softmax              | Input: [[8, 3]] -> Output: [8, 3]\n",
      "80 - AttentionFusion      | Input: <class 'tuple'> -> Output: [8, 192]\n",
      "81 - LayerNorm            | Input: [[8, 192]] -> Output: [8, 192]\n",
      "82 - Dropout              | Input: [[8, 192]] -> Output: [8, 192]\n",
      "83 - Linear               | Input: [[8, 192]] -> Output: [8, 64]\n",
      "84 - ReLU                 | Input: [[8, 64]] -> Output: [8, 64]\n",
      "85 - Linear               | Input: [[8, 64]] -> Output: [8, 1]\n",
      "86 - Softplus             | Input: [[8, 1]] -> Output: [8, 1]\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train this bitchass",
   "id": "5f55a8ea403b650d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T02:22:10.744888Z",
     "start_time": "2025-05-29T02:22:10.731574Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "config_real = {\n",
    "    'soil_in': 6,\n",
    "    'soil_hidden': 64,\n",
    "    'indoor_in': 10,\n",
    "    'weather_in': 8,\n",
    "    'crop_in': 5,\n",
    "    'branch_out': 64,\n",
    "    'fusion_dim': 128,\n",
    "    'output_dim': 1,\n",
    "    'device': device\n",
    "}"
   ],
   "id": "2b6df29301ba5d0d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T02:22:11.021041Z",
     "start_time": "2025-05-29T02:22:11.007158Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_metrics(preds, targets):\n",
    "    preds = preds.flatten()\n",
    "    targets = targets.flatten()\n",
    "    rmse = np.sqrt(mean_squared_error(targets, preds))\n",
    "    r2 = r2_score(targets, preds)\n",
    "    return rmse, r2"
   ],
   "id": "be8215246dec434f",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T02:45:23.935525Z",
     "start_time": "2025-05-29T02:45:23.923200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_and_validate(model, train_loader, val_loader, optimizer, criterion, device, epochs=20):\n",
    "    scaler = GradScaler(device='cuda')\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        train_preds, train_targets = [], []\n",
    "        train_loss = 0.0\n",
    "        for batch in train_loader:\n",
    "            soil_x, soil_mask, soil_delta, indoor_x, weather_x, crop_x, target_y = [b.to(device) for b in batch]\n",
    "            optimizer.zero_grad()\n",
    "            with autocast(device_type='cuda'):\n",
    "                outputs = model(soil_x, soil_mask, soil_delta, indoor_x, weather_x, crop_x)\n",
    "                loss = criterion(outputs, target_y)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(optimizer)  # AMP-safe unscale\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            train_loss += loss.item()\n",
    "            train_preds.append(outputs.detach().cpu().numpy())\n",
    "            train_targets.append(target_y.cpu().numpy())\n",
    "        # Metrics\n",
    "        train_preds = np.concatenate(train_preds)\n",
    "        train_targets = np.concatenate(train_targets)\n",
    "        train_rmse, train_r2 = compute_metrics(train_preds, train_targets)\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_preds, val_targets = [], []\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                soil_x, soil_mask, soil_delta, indoor_x, weather_x, crop_x, target_y = [b.to(device) for b in batch]\n",
    "                with autocast(device_type='cuda'):\n",
    "                    outputs = model(soil_x, soil_mask, soil_delta, indoor_x, weather_x, crop_x)\n",
    "                val_preds.append(outputs.cpu().numpy())\n",
    "                val_targets.append(target_y.cpu().numpy())\n",
    "        val_preds = np.concatenate(val_preds)\n",
    "        val_targets = np.concatenate(val_targets)\n",
    "        val_rmse, val_r2 = compute_metrics(val_preds, val_targets)\n",
    "        print(f\"[Epoch {epoch:03}] Train RMSE: {train_rmse:.4f}, R²: {train_r2:.4f} | Val RMSE: {val_rmse:.4f}, R²: {val_r2:.4f}\")"
   ],
   "id": "3c18dc82656217d3",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T02:45:24.694462Z",
     "start_time": "2025-05-29T02:45:24.681900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate(model, test_loader, device):\n",
    "    model.eval()\n",
    "    preds, targets = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            soil_x, soil_mask, soil_delta, indoor_x, weather_x, crop_x, target_y = [b.to(device) for b in batch]\n",
    "            outputs = model(soil_x, soil_mask, soil_delta, indoor_x, weather_x, crop_x)\n",
    "            preds.append(outputs.cpu().numpy())\n",
    "            targets.append(target_y.cpu().numpy())\n",
    "    preds = np.concatenate(preds)\n",
    "    targets = np.concatenate(targets)\n",
    "    rmse, r2 = compute_metrics(preds, targets)\n",
    "    print(f\"Test RMSE: {rmse:.4f}, R²: {r2:.4f}\")\n",
    "    return rmse, r2"
   ],
   "id": "5781568ad2a190ed",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-05-29T02:45:25.455396Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = HybridAgriModel(config_real).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = nn.MSELoss()\n",
    "train_and_validate(model, train_loader, val_loader, optimizer, criterion, device, epochs=20)"
   ],
   "id": "d9bd71b33da2dd17",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "evaluate(model, test_loader, device)",
   "id": "52840754ad8e85af",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
