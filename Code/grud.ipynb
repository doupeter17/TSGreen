{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "efd13a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e44b9a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thanh\\AppData\\Local\\Temp\\ipykernel_3536\\3084357586.py:5: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,14,15,17,18,20,22,23,25,27,29,31,33,35,37,39,41,43,44,45,47,49) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  climate = pd.read_csv(\"../AICU/GreenhouseClimate.csv\",encoding='utf-8')\n",
      "C:\\Users\\thanh\\AppData\\Local\\Temp\\ipykernel_3536\\3084357586.py:6: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,14,15,17,18,20,22,23,25,27,29,31,33,35,37,39,41,43,44,45,47,49) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  test_climate = pd.read_csv(\"../TheAutomators/GreenhouseClimate.csv\",encoding='utf-8')\n"
     ]
    }
   ],
   "source": [
    "weather = pd.read_csv(\"../Weather/Weather.csv\")\n",
    "weather = weather.drop(columns=[\"%time\"])\n",
    "resource = pd.read_csv(\"../AICU/Resources.csv\")\n",
    "test_resource = pd.read_csv(\"../TheAutomators/Resources.csv\")\n",
    "climate = pd.read_csv(\"../AICU/GreenhouseClimate.csv\",encoding='utf-8')\n",
    "test_climate = pd.read_csv(\"../TheAutomators/GreenhouseClimate.csv\",encoding='utf-8')\n",
    "production = pd.read_csv(\"../TheAutomators/Production.csv\",encoding='utf-8')\n",
    "production = production.astype(float)\n",
    "climate=climate.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f14f160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (132, 288, 10), y_train shape: (132, 1)\n"
     ]
    }
   ],
   "source": [
    "sample_per_day = 288 # 5 phút \n",
    "N_days = len(weather) // sample_per_day\n",
    "\n",
    "# Reshape input: [samples, timesteps, features]\n",
    "X_seq = []\n",
    "for i in range(N_days):\n",
    "    start = i * sample_per_day\n",
    "    end = start + sample_per_day\n",
    "    X_seq.append(weather.iloc[start:end].values)\n",
    "\n",
    "X_seq = np.array(X_seq)  # Shape: (166, 288, N_weather)\n",
    "y = resource[\"Heat_cons\"].values.reshape(-1,1)   # Shape: (166, N_resource)\n",
    "\n",
    "# Standarize\n",
    "scaler_X = StandardScaler()\n",
    "X_seq_scaled = np.array([scaler_X.fit_transform(day) for day in X_seq])\n",
    "X_seq_scaled = np.nan_to_num(X_seq_scaled)\n",
    "\n",
    "scaler_y = StandardScaler()\n",
    "y_scaled = scaler_y.fit_transform(y)\n",
    "y_scaled = np.nan_to_num(y_scaled)\n",
    "# Split train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_seq_scaled, y_scaled, test_size=0.2, random_state=42)\n",
    "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "413a9322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X_train and y_train are numpy arrays\n",
    "X_tensor = torch.tensor(X_train, dtype=torch.float32)  # shape: (132, 288, 10)\n",
    "y_tensor = torch.tensor(y_train, dtype=torch.float32)  # shape: (132, 1)\n",
    "\n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "80722691",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=input_size,   # 10\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True         # input: (batch, seq, feature)\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, seq_len, input_size)\n",
    "        out, _ = self.gru(x)         # out shape: (batch, seq_len, hidden_size)\n",
    "        out = out[:, -1, :]          # take last timestep: (batch, hidden_size)\n",
    "        out = self.fc(out)           # shape: (batch, output_size)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "00fba938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30] Loss: 9.2296 | R²: -0.0062\n",
      "Epoch [2/30] Loss: 8.8684 | R²: 0.0485\n",
      "Epoch [3/30] Loss: 8.2435 | R²: 0.0732\n",
      "Epoch [4/30] Loss: 9.0205 | R²: 0.0967\n",
      "Epoch [5/30] Loss: 7.7670 | R²: 0.1256\n",
      "Epoch [6/30] Loss: 7.4033 | R²: 0.1645\n",
      "Epoch [7/30] Loss: 7.0824 | R²: 0.2156\n",
      "Epoch [8/30] Loss: 6.5223 | R²: 0.2687\n",
      "Epoch [9/30] Loss: 6.2591 | R²: 0.3197\n",
      "Epoch [10/30] Loss: 6.2717 | R²: 0.3261\n",
      "Epoch [11/30] Loss: 6.9525 | R²: 0.3265\n",
      "Epoch [12/30] Loss: 5.6703 | R²: 0.3627\n",
      "Epoch [13/30] Loss: 5.7849 | R²: 0.3612\n",
      "Epoch [14/30] Loss: 5.6614 | R²: 0.3914\n",
      "Epoch [15/30] Loss: 4.9963 | R²: 0.4329\n",
      "Epoch [16/30] Loss: 4.9083 | R²: 0.4382\n",
      "Epoch [17/30] Loss: 4.8324 | R²: 0.4439\n",
      "Epoch [18/30] Loss: 4.8184 | R²: 0.4824\n",
      "Epoch [19/30] Loss: 5.0736 | R²: 0.5056\n",
      "Epoch [20/30] Loss: 4.2379 | R²: 0.5312\n",
      "Epoch [21/30] Loss: 4.5542 | R²: 0.5355\n",
      "Epoch [22/30] Loss: 4.0754 | R²: 0.5405\n",
      "Epoch [23/30] Loss: 4.6314 | R²: 0.5172\n",
      "Epoch [24/30] Loss: 3.6266 | R²: 0.5952\n",
      "Epoch [25/30] Loss: 3.9645 | R²: 0.6141\n",
      "Epoch [26/30] Loss: 3.2880 | R²: 0.6212\n",
      "Epoch [27/30] Loss: 3.6342 | R²: 0.6399\n",
      "Epoch [28/30] Loss: 3.2605 | R²: 0.6503\n",
      "Epoch [29/30] Loss: 3.6111 | R²: 0.6504\n",
      "Epoch [30/30] Loss: 3.6222 | R²: 0.6672\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = GRUModel(input_size=10, hidden_size=64, num_layers=2, output_size=1).to(device)\n",
    "criterion = nn.MSELoss()  # or BCEWithLogitsLoss() if binary classification\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 30\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    for batch_X, batch_y in dataloader:\n",
    "        batch_X = batch_X.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Store predictions and targets\n",
    "        all_preds.append(outputs.detach().cpu())\n",
    "        all_targets.append(batch_y.detach().cpu())\n",
    "\n",
    "    # Compute R² after entire epoch\n",
    "    all_preds = torch.cat(all_preds).numpy()\n",
    "    all_targets = torch.cat(all_targets).numpy()\n",
    "    r2 = r2_score(all_targets, all_preds)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] Loss: {total_loss:.4f} | R²: {r2:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a2d09149",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'gru_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "20a39182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GRUNet(\n",
       "  (gru): GRU(10, 64, num_layers=2, batch_first=True)\n",
       "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define your GRU model class (should be same as training)\n",
    "class GRUNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(GRUNet, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.gru(x, h0)\n",
    "        out = self.fc(out[:, -1, :])  # Use last timestep output\n",
    "        return out\n",
    "\n",
    "# Initialize model\n",
    "model = GRUNet(input_size=10, hidden_size=64, num_layers=2, output_size=1)\n",
    "model.load_state_dict(torch.load('gru_model.pth'))\n",
    "model.eval()  # Set to evaluation mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "92776019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test R²: -0.6760\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Assume device, model, scaler_y, X_test, y_test are defined already\n",
    "\n",
    "# Prepare X_test tensor and move to device\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "model.to(device)\n",
    "# Put model in eval mode and predict\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_scaled = model(X_test_tensor).cpu().numpy()\n",
    "# Inverse transform predictions and true targets back to original scale\n",
    "y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
    "y_test_original = scaler_y.inverse_transform(y_test)\n",
    "\n",
    "# Calculate and print R² score\n",
    "r2 = r2_score(y_test_original, y_pred)\n",
    "print(f\"Test R²: {r2:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
