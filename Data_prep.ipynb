{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9968d2597cf3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim import Adam\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from torch.utils.data import random_split\n",
    "from torch.amp import autocast, GradScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_paths_2 = {\n",
    "    \"GreenhouseClimate\": \"/home/cuongdo/AICU/GreenhouseClimate.csv\",\n",
    "    \"GrodanSens\": \"/home/cuongdo/AICU/GrodanSens.csv\",\n",
    "    \"Resources\": \"/home/cuongdo/AICU/Resources.csv\",\n",
    "    \"Weather\": \"/home/cuongdo/Weather/Weather.csv\",\n",
    "    \"CropParameters\": \"/home/cuongdo/AICU/CropParameters.csv\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b82c5bfeb4f6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_2 = {}\n",
    "for name, path in file_paths_2.items():\n",
    "    df_2 = pd.read_csv(path, low_memory=False)\n",
    "    df_2.columns = df_2.columns.str.strip().str.replace('\\t', '')\n",
    "    if '%time' in df_2.columns or '%Time' in df_2.columns:\n",
    "            time_col = '%time' if '%time' in df_2.columns else '%Time'\n",
    "            df_2[time_col] = pd.to_numeric(df_2[time_col], errors='coerce')\n",
    "            df_2['Date'] = pd.to_datetime(df_2[time_col], origin='1899-12-30', unit='D')\n",
    "    elif 'time' in df.columns:\n",
    "        df_2['time'] = pd.to_numeric(df_2['time'], errors='coerce')\n",
    "        df_2['Date'] = pd.to_datetime(df_2['time'], origin='1899-12-30', unit='D')\n",
    "    elif 'Date' in df_2.columns:\n",
    "        if pd.api.types.is_numeric_dtype(df_2['Date']):\n",
    "            df_2['Date'] = pd.to_datetime(df_2['Date'], origin='1899-12-30', unit='D', errors='coerce')\n",
    "        else:\n",
    "            df_2['Date'] = pd.to_datetime(df_2['Date'], errors='coerce')\n",
    "    else:\n",
    "        df_2['Date'] = pd.NaT\n",
    "    df_2.loc[:, df_2.columns != 'Date'] = df_2.loc[:, df_2.columns != 'Date'].apply(pd.to_numeric, errors='coerce')\n",
    "    dfs_2[name] = df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7457a80f2c420dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "soil_cols = ['EC_slab1', 'EC_slab2', 'WC_slab1', 'WC_slab2', 't_slab1', 't_slab2']\n",
    "indoor_cols = ['Tair', 'Rhair', 'CO2air', 'HumDef', 'PipeLow', 'VentLee', 'Ventwind', 'Tot_PAR', 'Tot_PAR_Lamps', 'EC_drain_PC']\n",
    "weather_cols = ['Tout', 'Rhout', 'Iglob', 'PARout', 'Pyrgeo', 'Rain', 'Winddir', 'Windsp']\n",
    "crop_cols = ['Stem_elong', 'Stem_thick', 'Cum_trusses', 'stem_dens', 'plant_dens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79eae2eff4a7e2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_sliding(df, cols, steps, stride=1):\n",
    "    df = df.copy()\n",
    "    df[cols] = df[cols].astype(np.float32)\n",
    "    arr = df[cols].values\n",
    "    if len(arr) < steps:\n",
    "        return np.empty((0, steps, len(cols)))\n",
    "    windows = [arr[i:i + steps] for i in range(0, len(arr) - steps + 1, stride)]\n",
    "    return np.stack(windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6167d3e59b816e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_delta(mask):\n",
    "    B, T, D = mask.shape\n",
    "    delta = np.zeros((B, T, D), dtype=np.float32)\n",
    "    for b in range(B):\n",
    "        for d in range(D):\n",
    "            last_obs = 0\n",
    "            for t in range(T):\n",
    "                if mask[b, t, d] == 1:\n",
    "                    delta[b, t, d] = 0\n",
    "                    last_obs = 0\n",
    "                else:\n",
    "                    last_obs += 1\n",
    "                    delta[b, t, d] = last_obs\n",
    "    return delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dbd786eac5344d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_2 = dfs_2['GrodanSens'].copy()\n",
    "base_2 = base_2.dropna(subset=['Date']).sort_values('Date').reset_index(drop=True)\n",
    "merge_partners = ['GreenhouseClimate', 'Weather', 'CropParameters']\n",
    "for name in merge_partners:\n",
    "    df = dfs_2[name].copy().dropna(subset=['Date']).sort_values('Date')\n",
    "    if '%time' in df.columns:\n",
    "        df.drop(columns=['%time'], inplace=True)\n",
    "    try:\n",
    "        base_2 = pd.merge_asof(base_2, df, on='Date', direction='nearest', tolerance=pd.Timedelta('1D'))\n",
    "    except ValueError as e:\n",
    "        print(f\"[ERROR] Skipped {name} during merge: {e}\")\n",
    "resources_df = dfs_2['Resources'].copy().dropna(subset=['Date']).sort_values('Date').reset_index(drop=True)\n",
    "resources_df['Energy'] = resources_df[['Heat_cons', 'ElecHigh', 'ElecLow']].astype(np.float32).sum(axis=1)\n",
    "resources_df = resources_df[['Date', 'Energy']]\n",
    "resources_df['Date'] = resources_df['Date'].dt.floor('D')\n",
    "base_2['Date'] = base_2['Date'].dt.floor('D')\n",
    "base_2 = pd.merge_asof(base_2.sort_values('Date'), resources_df, on='Date', direction='nearest', tolerance=pd.Timedelta('1D'))\n",
    "base_2 = base_2.dropna(subset=['Energy']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39c84d786160c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 288  # full day (5 min x 288 = 24 hours)\n",
    "# --- Sliding window time-series ---\n",
    "soil_data_2 = reshape_sliding(base_2, soil_cols, steps=steps, stride=1)\n",
    "soil_mask_2 = (~np.isnan(soil_data_2)).astype(np.float32)\n",
    "soil_delta_2 = compute_delta(soil_mask_2)\n",
    "soil_data_2 = np.nan_to_num(soil_data_2)\n",
    "indoor_data_2 = reshape_sliding(base_2, indoor_cols, steps=steps, stride=1)\n",
    "weather_data_2 = reshape_sliding(base_2, weather_cols, steps=steps, stride=1)\n",
    "# --- Crop is static per day, align with sliding windows ---\n",
    "crop_data_raw = base_2[crop_cols].astype(np.float32).to_numpy()\n",
    "crop_data_2 = crop_data_raw[steps - 1:]  # align with window end points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8e1a6ce95bc360",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_end_dates = base_2['Date'].iloc[steps - 1:].reset_index(drop=True)\n",
    "targets = []\n",
    "valid_indices = []\n",
    "for i in range(len(soil_data_2)):\n",
    "    end_date = window_end_dates[i].floor('D')\n",
    "    match = resources_df[resources_df['Date'] == (end_date + pd.Timedelta(days=1))]\n",
    "    if not match.empty:\n",
    "        energy_val = match['Energy'].values[0]\n",
    "        if not np.isnan(energy_val):\n",
    "            targets.append(energy_val.astype(np.float32))\n",
    "            valid_indices.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bc4202b665c64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if valid_indices:\n",
    "    soil_data_2 = soil_data_2[valid_indices]\n",
    "    soil_mask_2 = soil_mask_2[valid_indices]\n",
    "    soil_delta_2 = soil_delta_2[valid_indices]\n",
    "    indoor_data_2 = indoor_data_2[valid_indices]\n",
    "    weather_data_2 = weather_data_2[valid_indices]\n",
    "    crop_data_2 = crop_data_2[valid_indices]\n",
    "    targets = torch.tensor(np.array(targets), dtype=torch.float32).unsqueeze(1)\n",
    "    dataset_2 = TensorDataset(\n",
    "        torch.tensor(soil_data_2, dtype=torch.float32),\n",
    "        torch.tensor(soil_mask_2, dtype=torch.float32),\n",
    "        torch.tensor(soil_delta_2, dtype=torch.float32),\n",
    "        torch.tensor(indoor_data_2, dtype=torch.float32),\n",
    "        torch.tensor(weather_data_2, dtype=torch.float32),\n",
    "        torch.tensor(crop_data_2, dtype=torch.float32),\n",
    "        targets\n",
    "    )\n",
    "    dataloader_2 = DataLoader(dataset_2, batch_size=512, shuffle=True, num_workers=40, pin_memory=True)\n",
    "    print(f\"Dataloader ready: {len(dataset_2)} labeled windows with next-day energy targets\")\n",
    "else:\n",
    "    print(\"No labeled windows found for energy prediction.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496f4dca99c2a07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lengths\n",
    "total_len = len(dataset_2)\n",
    "train_len = int(0.8 * total_len)\n",
    "val_len = int(0.1 * total_len)\n",
    "test_len = total_len - train_len - val_len  # handle rounding\n",
    "# Split dataset\n",
    "train, val, test = random_split(dataset_2, [train_len, val_len, test_len])\n",
    "# DataLoaders\n",
    "batch_size = 512\n",
    "train_loader_2 = DataLoader(train, batch_size=batch_size, shuffle=True, num_workers=40, pin_memory=True, prefetch_factor = 4)\n",
    "val_loader_2 = DataLoader(val, batch_size=batch_size, shuffle=False, num_workers=40, pin_memory=True, prefetch_factor = 4)\n",
    "test_loader_2 = DataLoader(test, batch_size=batch_size, shuffle=False, num_workers=40, pin_memory=True, prefetch_factor = 4)\n",
    "print(f\"Split sizes â€” Train: {len(train)}, Val: {len(val)}, Test: {len(test)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
