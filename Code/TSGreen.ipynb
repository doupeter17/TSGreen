{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3772f54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "20876057",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dir):\n",
    "    data_dict = {}\n",
    "    if not os.path.exists(dir):\n",
    "        raise FileExistsError(f\"Directory not found.\")\n",
    "    for filename in os.listdir(dir):\n",
    "        if filename.endswith('.csv'):\n",
    "            filepath = os.path.join(dir, filename)\n",
    "            df = pd.read_csv(filepath)\n",
    "            cleaned_column = {col: col.strip('%').strip() for col in df.columns}\n",
    "            df.rename(columns=cleaned_column, inplace =True)\n",
    "            df = df.astype(\"float\")\n",
    "            data_dict[filename] = df\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc53793",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "def create_block_missingness(df, n_blocks=2, block_size_fraction=0.05, seed=None):\n",
    "    \"\"\"Creates consecutive blocks of missing values to simulate outages.\"\"\"\n",
    "    df_with_missing = df.copy()\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    n_rows = len(df)\n",
    "    block_size = int(n_rows * block_size_fraction)\n",
    "    if block_size == 0:\n",
    "        block_size = 1 # Ensure at least one value is removed\n",
    "\n",
    "    for _ in range(n_blocks):\n",
    "        start_index = np.random.randint(0, n_rows - block_size)\n",
    "        end_index = start_index + block_size\n",
    "        # Create a boolean mask for the block\n",
    "        mask = df_with_missing.index.to_series().between(df.index[start_index], df.index[end_index])\n",
    "        # Apply the mask to all columns\n",
    "        df_with_missing[mask] = np.nan\n",
    "        \n",
    "    return df_with_missing\n",
    "\n",
    "def create_missing_value(df, missing_fraction=0.1, seed=None):    \n",
    "    df_with_missing = df.copy()\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    mask = np.random.rand(*df.shape) < missing_fraction\n",
    "    df_with_missing = df_with_missing.mask(mask)\n",
    "    \n",
    "    return df_with_missing\n",
    "\n",
    "def longest_notna(df):\n",
    "    notna_mask = df.notna().all(axis=1)  \n",
    "    group_id = (notna_mask != notna_mask.shift()).cumsum()\n",
    "\n",
    "    # Filter only the True blocks = Notna \n",
    "    valid_blocks = df[notna_mask].copy()\n",
    "    valid_blocks['group'] = group_id[notna_mask]\n",
    "\n",
    "    # Find the longest group\n",
    "    longest_group = valid_blocks['group'].value_counts().idxmax()\n",
    "\n",
    "    # Return the longest block\n",
    "    return valid_blocks[valid_blocks['group'] == longest_group].drop(columns='group')\n",
    "\n",
    "def knn_mean(ts, n=4):\n",
    "    ts = np.array(ts)\n",
    "    out = np.copy(ts)\n",
    "    for i, val in enumerate(ts):\n",
    "        if np.isnan(val):\n",
    "            lower = max(0, i - n)\n",
    "            upper = min(len(ts), i + n + 1)\n",
    "            neighbors = ts[lower:i].tolist() + ts[i+1:upper].tolist()\n",
    "            neighbors = [x for x in neighbors if not np.isnan(x)]\n",
    "            out[i] = np.mean(neighbors) if neighbors else np.nan\n",
    "    return out\n",
    "\n",
    "def seasonal_mean(series, season_lag, lr=0.7):\n",
    "\n",
    "    out = series.copy()\n",
    "    for i in range(len(series)):\n",
    "        if pd.isna(series.iloc[i]):\n",
    "            # Previous seasonal values\n",
    "            prev_seasons = series.iloc[i - season_lag::-season_lag]\n",
    "            if pd.isna(prev_seasons.mean()):\n",
    "                # Combine previous and forward seasonal values\n",
    "                forward_seasons = series.iloc[i + season_lag::season_lag]\n",
    "                seasonal_values = pd.concat([prev_seasons, forward_seasons])\n",
    "            else:\n",
    "                seasonal_values = prev_seasons\n",
    "            out.iloc[i] = seasonal_values.mean() * lr\n",
    "    return out\n",
    "\n",
    "def handle_missing(df, percent):\n",
    "    # Remove columns have missing data above threshhold.\n",
    "    missing_percent = df.isnull().mean()\n",
    "    df_filtered = df.loc[:, missing_percent<percent]\n",
    "    print(f\"Filtered all features having missing value > 20%\")\n",
    "    print(f\"Number of features removed: {len(df.columns)-len(df_filtered.columns)}\")\n",
    "\n",
    "    result_df = pd.DataFrame(columns = [\"Feature\",\"Method\",\"Result\"])\n",
    "\n",
    "    # After filtered, dataframe now has only columns that can\n",
    "    for col in df_filtered.columns:\n",
    "\n",
    "        feature_data = df_filtered[[col]]\n",
    "        ground_truth = longest_notna(feature_data)\n",
    "        missing_df = create_missing_value(ground_truth)\n",
    "        missing_df = create_block_missingness(missing_df)\n",
    "\n",
    "        imputation_dict = {}\n",
    "        imputation_dict[\"backward/forward_fill\"] = missing_df.bfill().ffill()\n",
    "        imputation_dict[\"linear_interpolation\"] = missing_df.interpolate(method = 'linear', axis = 0, limit_direction = 'forward')\n",
    "        imputation_dict[\"spline_interpolation\"] = missing_df.interpolate(method = 'spline', order=3)        \n",
    "        imputation_dict[\"quadaric_interpolation\"] = missing_df.interpolate(method = 'cubicspline')\n",
    "        imputation_dict[\"knn_mean\"] = knn_mean(missing_df, 8)\n",
    "        imputation_dict[\"seasonal_mean\"] = seasonal_mean(missing_df[col], season_lag = 12, lr = 1.25)\n",
    "        imputation_dict[\"linear_ffill\"] = missing_df.interpolate(method='linear').ffill()\n",
    "        imputation_dict[\"linear_bfill\"] = missing_df.interpolate(method='linear').bfill()\n",
    "        imputation_dict[\"spline_bfill_ffill\"] = missing_df.interpolate(method='spline', order = 3).bfill().ffill()\n",
    "        imputation_dict[\"seasonal_linear_ffill\"] = seasonal_mean(missing_df[col], season_lag = 12, lr = 1.25).interpolate(method='linear').ffill()\n",
    "\n",
    "        for key, pred_value in imputation_dict.items():\n",
    "            if pd.isna(np.array(pred_value)).any():\n",
    "                r2 = np.nan\n",
    "            else:\n",
    "                r2 = r2_score(ground_truth, pred_value)\n",
    "            result_df.loc[len(result_df)]=[col,key,r2]\n",
    "            \n",
    "    best_methods_idx = result_df.groupby('Feature')['Result'].idxmax()\n",
    "    best_methods_df = result_df.loc[best_methods_idx]\n",
    "    print(\"Highest R¬≤ method per feature:\")\n",
    "    print(best_methods_df[['Feature', 'Method', 'Result']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85f7ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TSImputer:\n",
    "    def __init__(self, strategy = 'r2'):\n",
    "        if strategy not in ['r2', 'mae', 'mse']:\n",
    "            raise ValueError(\"Strategy must be either 'r2' or 'mae'\")\n",
    "        self.strategy = strategy\n",
    "        self.verbose = verbose\n",
    "        self.best_methods_ = {} # L∆∞u tr·ªØ ph∆∞∆°ng ph√°p t·ªët nh·∫•t cho m·ªói c·ªôt\n",
    "        self._define_pipelines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ec387980",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thanh\\AppData\\Local\\Temp\\ipykernel_14736\\297146114.py:8: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,14,15,17,18,20,22,23,25,27,29,31,33,35,37,39,41,43,44,45,47,49) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded data from Digilog\n",
      "Filtered all features having missing value > 20%\n",
      "Number of features removed: 4\n",
      "üîù Highest R¬≤ method per feature:\n",
      "                         Feature                  Method    Result\n",
      "17                    AssimLight            linear_bfill  0.807793\n",
      "21                      BlackScr    linear_interpolation  0.867427\n",
      "30                        CO2air   backward/forward_fill  0.915223\n",
      "42                       Cum_irr    spline_interpolation  0.863713\n",
      "51                   EC_drain_PC    linear_interpolation  0.999405\n",
      "63                         EnScr  quadaric_interpolation  0.999769\n",
      "71                        HumDef    linear_interpolation  0.934009\n",
      "81                      PipeGrow    linear_interpolation  0.990942\n",
      "91                       PipeLow    linear_interpolation  0.816963\n",
      "100                        Rhair   backward/forward_fill  0.979228\n",
      "111                         Tair    linear_interpolation  0.945754\n",
      "121                      Tot_PAR    linear_interpolation  0.865389\n",
      "130                Tot_PAR_Lamps   backward/forward_fill  0.929048\n",
      "145                      VentLee           seasonal_mean  0.725094\n",
      "151                     Ventwind    linear_interpolation  0.918715\n",
      "163                     assim_sp  quadaric_interpolation  0.872646\n",
      "171                    assim_vip    linear_interpolation  0.862784\n",
      "181                      co2_dos    linear_interpolation  0.911457\n",
      "191                       co2_sp    linear_interpolation  0.875285\n",
      "205                      co2_vip           seasonal_mean  0.796678\n",
      "212                        dx_sp    spline_interpolation  0.784972\n",
      "221                       dx_vip    linear_interpolation  0.994847\n",
      "230                  int_blue_sp   backward/forward_fill  0.964026\n",
      "241                int_farred_sp    linear_interpolation  0.963286\n",
      "251                   int_red_sp    linear_interpolation  0.902503\n",
      "261                 int_white_sp    linear_interpolation  0.967697\n",
      "271                  pH_drain_PC    linear_interpolation  0.995611\n",
      "281                  scr_blck_sp    linear_interpolation  0.806745\n",
      "297                 scr_blck_vip            linear_bfill  0.871703\n",
      "303                  scr_enrg_sp  quadaric_interpolation  0.999869\n",
      "317                 scr_enrg_vip            linear_bfill  0.860892\n",
      "321                t_grow_min_sp    linear_interpolation  0.999113\n",
      "330               t_grow_min_vip   backward/forward_fill  1.000000\n",
      "341                    t_heat_sp    linear_interpolation  0.932083\n",
      "357                   t_heat_vip            linear_bfill  0.967427\n",
      "363                t_rail_min_sp  quadaric_interpolation  0.781089\n",
      "371               t_rail_min_vip    linear_interpolation  0.999063\n",
      "383                    t_vent_sp  quadaric_interpolation  0.701891\n",
      "390                t_ventlee_vip   backward/forward_fill  0.942847\n",
      "407               t_ventwind_vip            linear_bfill  0.917617\n",
      "8                           time      spline_bfill_ffill  1.000000\n",
      "410                    water_sup   backward/forward_fill  0.947214\n",
      "421   water_sup_intervals_sp_min    linear_interpolation  0.869238\n",
      "437  water_sup_intervals_vip_min            linear_bfill  0.858622\n",
      "440            window_pos_lee_sp   backward/forward_fill  1.000000\n",
      "450           window_pos_lee_vip   backward/forward_fill  1.000000\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = '../'\n",
    "GREENHOUSE_TEAM = \"Digilog\"\n",
    "\n",
    "team_folder_path = os.path.join(DATA_PATH,GREENHOUSE_TEAM)\n",
    "team_df = load_data(team_folder_path)\n",
    "\n",
    "print(f\"Successfully loaded data from {GREENHOUSE_TEAM}\")\n",
    "\n",
    "handle_missing(team_df[\"GreenhouseClimate.csv\"], 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0717f445",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "def adf_test(timeseries):\n",
    "    print('Result of Augmented Dickey Fuller: ')\n",
    "    df_test= adfuller(timeseries, autolag = \"AIC\")\n",
    "    df_output = pd.Series(df_test[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations'])\n",
    "    for key, value in df_test[4].items():\n",
    "        df_output['Critical Value (%s)'%key] = value\n",
    "    print(df_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "28c0f22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of Augmented Dickey Fuller: \n",
      "Test Statistic           -1.313535e+01\n",
      "p-value                   1.466031e-24\n",
      "#Lags Used                5.300000e+01\n",
      "Number of Observations    4.680100e+04\n",
      "Critical Value (1%)      -3.430490e+00\n",
      "Critical Value (5%)      -2.861602e+00\n",
      "Critical Value (10%)     -2.566803e+00\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "adf_test(df_climate[\"int_red_sp\"].astype(\"float\").dropna())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
